{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinKarev/ML_for_DNK/blob/main/Seminar_1_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl75g1LWI1SW"
      },
      "source": [
        "## Спектральное представление речевого сигнала. Введение в цифровую обработку сигналов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04ubJi29I1SZ"
      },
      "source": [
        "Рассмотрим основы работы с речевыми сигналами с использованием библиотеки `torchaudio`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2eclaNTI1SZ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import matplotlib\n",
        "import torch\n",
        "import torchaudio\n",
        "from scipy.io import wavfile\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "matplotlib.rc('xtick', labelsize=16)\n",
        "matplotlib.rc('ytick', labelsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFzn40EaI1Sa"
      },
      "outputs": [],
      "source": [
        "wav, sr = torchaudio.load('data/LJ001-0001.wav')\n",
        "print(f'Sample rate = {sr}, Wave = {wav}, Type: {wav.dtype}, Shape: {wav.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D2mL7AQI1Sb"
      },
      "outputs": [],
      "source": [
        "def visualize_audio(wav: torch.Tensor, sr: int = 22050):\n",
        "    # Усредняем при необходимости каналы\n",
        "    if wav.dim() == 2:\n",
        "        # Преобразуем в моно\n",
        "        wav = wav.mean(dim=0)\n",
        "\n",
        "    time_scale = torch.arange(wav.shape[0]) / sr\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.plot(time_scale, wav, alpha=.7, c='green')\n",
        "    plt.grid()\n",
        "    plt.xlabel('Time, seconds', size=20)\n",
        "    plt.ylabel('Amplitude', size=20)\n",
        "    plt.show()\n",
        "\n",
        "    display.display(display.Audio(wav, rate=sr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF4PBzm4I1Sb"
      },
      "outputs": [],
      "source": [
        "visualize_audio(wav)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pyugEPI1Sb"
      },
      "source": [
        "### Fast Fourier Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F97bPxIHI1Sb"
      },
      "outputs": [],
      "source": [
        "n_fft = 1024\n",
        "spectrum = torch.fft.rfft(wav, n=n_fft)\n",
        "print(spectrum.dtype)\n",
        "\n",
        "spectrogram = spectrum.abs().pow(2)\n",
        "spectrogram_2 = torch.view_as_real(spectrum).norm(dim=-1).pow(2)\n",
        "\n",
        "print(torch.allclose(spectrogram, spectrogram_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axRW-S8fI1Sc"
      },
      "source": [
        "Изобразим спектр мощности (квадратов магнитуд) первых 1024 отсчетов нашего сигнала."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChjjcDRyI1Sc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(spectrogram.squeeze(), c='green')\n",
        "plt.grid()\n",
        "plt.xlabel('Frequency, Hz', size=20)\n",
        "plt.ylabel('Magnitude$^2$', size=20)\n",
        "plt.xticks(size=16)\n",
        "plt.yticks(size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn9KmuC4I1Sc"
      },
      "source": [
        "Применим оконную функцию Ханна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7ySCOs9I1Sc"
      },
      "outputs": [],
      "source": [
        "window_size = n_fft\n",
        "window = torch.hann_window(window_size)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(window, c='green')\n",
        "plt.xticks(size=16)\n",
        "plt.yticks(size=16)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTnwgbzCI1Sc"
      },
      "outputs": [],
      "source": [
        "clipped_wav = wav[:, :window_size]\n",
        "windowed_clipped_wav = window * clipped_wav\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "axes[0].plot(clipped_wav.squeeze(), c='green')\n",
        "axes[0].set_title('Raw Audio', size=20)\n",
        "\n",
        "axes[1].plot(windowed_clipped_wav.squeeze(), c='green')\n",
        "axes[1].set_title('Windowed Audio', size=20)\n",
        "\n",
        "for i in range(2):\n",
        "    axes[i].grid()\n",
        "    axes[i].set_xlabel('Time', size=20)\n",
        "    axes[i].set_ylabel('Amplitude', size=20)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBG4lJN5I1Sd"
      },
      "outputs": [],
      "source": [
        "spectrogram = torch.fft.rfft(clipped_wav).abs().pow(2)\n",
        "windowed_spectrogram = torch.fft.rfft(windowed_clipped_wav).abs().pow(2)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "axes[0].plot(spectrogram.squeeze(), c='green')\n",
        "axes[0].set_title('Spectrogram of Raw Audio', size=20)\n",
        "\n",
        "axes[1].plot(windowed_spectrogram.squeeze(), c='green')\n",
        "axes[1].set_title('Spectrogram of Windowed Audio', size=20)\n",
        "\n",
        "for i in range(2):\n",
        "    axes[i].grid()\n",
        "    axes[i].set_xlabel('Frequency (Hz)', size=20)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VbiJT68I1Sd"
      },
      "source": [
        "STFT (short-time Fourier transform) для всего сигнала"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM--XIycI1Sd"
      },
      "outputs": [],
      "source": [
        "n_fft = 1024\n",
        "window_size = n_fft\n",
        "hop_size = 256\n",
        "window = torch.hann_window(n_fft)\n",
        "\n",
        "spectrum = torch.stft(\n",
        "    wav,\n",
        "    n_fft=n_fft,\n",
        "    hop_length=hop_size,\n",
        "    win_length=window_size,\n",
        "    window=window,\n",
        "    center=False,\n",
        "    onesided=True,\n",
        "    return_complex=True\n",
        ")\n",
        "\n",
        "print(f'Shape of spectrum: {spectrum.shape}, Type of spectrum: {spectrum.dtype}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeLp1aI5I1Sd"
      },
      "outputs": [],
      "source": [
        "spectrogram_real_imag = torch.view_as_real(spectrum)\n",
        "print(f'Shape of spectrum: {spectrogram_real_imag.shape}, Type of spectrum: {spectrogram_real_imag.dtype}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXkd2qULI1Se"
      },
      "outputs": [],
      "source": [
        "spectrogram = spectrogram_real_imag.norm(dim=-1).pow(2)\n",
        "print(f'Shape of spectrum: {spectrogram.shape}, Type of spectrum: {spectrogram.dtype}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e02Z8elI1Se"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(spectrogram.squeeze().log()) # logarithmic scale\n",
        "plt.xlabel('Time', size=20)\n",
        "plt.ylabel('Frequency (Hz)', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l2igncDI1Se"
      },
      "source": [
        "Мел-шкала частот"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVIoMrueI1Se"
      },
      "outputs": [],
      "source": [
        "mel_scaler = torchaudio.transforms.MelScale(\n",
        "    n_mels=80,\n",
        "    sample_rate=22_050,\n",
        "    n_stft=n_fft // 2 + 1\n",
        ")\n",
        "\n",
        "print(f'Shape of mel_scaler: {mel_scaler.fb.shape}')\n",
        "print(mel_scaler.fb.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GxoKYE4I1Se"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(mel_scaler.fb.T)\n",
        "plt.xlabel('Hertz Scale', size=20)\n",
        "plt.ylabel('Mels Scale', size=20)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrfvA9jRI1Se"
      },
      "outputs": [],
      "source": [
        "mel_spectrogram = mel_scaler(spectrogram)\n",
        "print(f'Shape of mel spectrogram: {mel_spectrogram.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTvcjSxWI1Sf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(mel_spectrogram.squeeze().log())\n",
        "plt.xlabel('Time', size=20)\n",
        "plt.ylabel('Mels', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVlA_FbvI1Sf"
      },
      "outputs": [],
      "source": [
        "# torchaudio.transforms.MelSpectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9esyZZ-KI1Sf"
      },
      "source": [
        "## Аугментации речи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pixuKLNsI1Sf"
      },
      "source": [
        "Рассмотрим основные виды аугментаций, применяемых к речевым сигналам. В данном примере рассматриваются только примеры на основе библиотек `torchaudio` и `librosa`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT-J9V2FI1Sf"
      },
      "source": [
        "### 1. Гауссов шум"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvXVj37UI1Sf"
      },
      "outputs": [],
      "source": [
        "from torch import distributions\n",
        "\n",
        "noiser = distributions.Normal(0, 0.05)\n",
        "augumented_wav_1 = wav + noiser.sample(wav.size())\n",
        "\n",
        "visualize_audio(augumented_wav_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZAzMfuTI1Sf"
      },
      "source": [
        "### 2. Растяжение/сжатие по временной шкале"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVDt69VbI1Sf"
      },
      "outputs": [],
      "source": [
        "# naive approach (don't do this!)\n",
        "\n",
        "simple_stretch = wav[:, ::2]\n",
        "visualize_audio(simple_stretch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ_sILzuI1Sg"
      },
      "outputs": [],
      "source": [
        "# first approach\n",
        "\n",
        "import librosa\n",
        "\n",
        "augumented_wav_2 = librosa.effects.time_stretch(wav.squeeze().numpy(), rate=2)\n",
        "augumented_wav_2 = torch.from_numpy(augumented_wav_2)\n",
        "visualize_audio(augumented_wav_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaNVmttyI1Sg"
      },
      "outputs": [],
      "source": [
        "# second approach\n",
        "n_fft = 400\n",
        "\n",
        "stretcher = torch.nn.Sequential(\n",
        "    torchaudio.transforms.Spectrogram(n_fft=n_fft, power=None),\n",
        "    torchaudio.transforms.TimeStretch(n_freq = n_fft // 2 + 1, fixed_rate=2.0),\n",
        "    torchaudio.transforms.InverseSpectrogram(n_fft=n_fft),\n",
        ")\n",
        "\n",
        "augumented_wav_2_v2 = stretcher(wav)\n",
        "visualize_audio(augumented_wav_2_v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PXvoERDI1Sg"
      },
      "source": [
        "### Изменение частоты голоса (pitch shifting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxC1zM2GI1Sg"
      },
      "outputs": [],
      "source": [
        "augumented_wav_3 = librosa.effects.pitch_shift(wav.squeeze().numpy(), sr=sr, n_steps=-5)\n",
        "augumented_wav_3 = torch.from_numpy(augumented_wav_3)\n",
        "\n",
        "visualize_audio(augumented_wav_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5EWszfOI1Sh"
      },
      "source": [
        "### Изменение громкости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw8NDq62I1Sh"
      },
      "outputs": [],
      "source": [
        "voler = torchaudio.transforms.Vol(gain=0.2, gain_type='amplitude')\n",
        "augumented_wav_4 = voler(wav)\n",
        "visualize_audio(augumented_wav_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Wq9x-TI1Sh"
      },
      "source": [
        "### Добавление реверберации\n",
        "\n",
        "Производится за счет свертки импульсной характеристики помещения с аудиосигналом. Подробнее можно почитать здесь:\n",
        "\n",
        "1) https://www.acousticalsurfaces.com/acoustic_IOI/reverberation.htm\n",
        "2) https://www.sonic-shield.com/echo-vs-reverberation\n",
        "3) https://en.wikipedia.org/wiki/Convolution_reverb\n",
        "4) https://danielpovey.com/files/2017_icassp_reverberation.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSym5FT0I1Si"
      },
      "outputs": [],
      "source": [
        "rir, rir_sr = torchaudio.load('data/rirs/greathall.wav')\n",
        "visualize_audio(rir, rir_sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCfZyUTwI1Si"
      },
      "outputs": [],
      "source": [
        "def simulate(audio: torch.Tensor, rir: torch.Tensor):\n",
        "    left_pad = right_pad = rir.shape[-1] - 1\n",
        "\n",
        "    # Разворачиваем ядро свертки, так как torch.conv вычисляет кросс-корреляцию, а не свертку\n",
        "    flipped_rir = rir.squeeze().flip(0)\n",
        "\n",
        "    audio = torch.nn.functional.pad(audio, [left_pad, right_pad]).view(1, 1, -1)\n",
        "    convolved_audio = torch.conv1d(audio, flipped_rir.view(1, 1, -1)).squeeze()\n",
        "\n",
        "    # peak normalization\n",
        "    if convolved_audio.abs().max() > 1:\n",
        "        convolved_audio /= convolved_audio.abs().max()\n",
        "\n",
        "    return convolved_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aW37w5wI1Si"
      },
      "outputs": [],
      "source": [
        "augumented_wav_5 = simulate(wav, rir)\n",
        "visualize_audio(augumented_wav_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBN4uItoI1Sj"
      },
      "source": [
        "### Добавление фонового шума\n",
        "\n",
        "Нужно, если мы хотим добиться устойчивости нашей модели к шуму, сопровождающему записанный аудиосигнал. Можно почитать:\n",
        "\n",
        "1) https://medium.com/analytics-vidhya/adding-noise-to-audio-clips-5d8cee24ccb8\n",
        "2) https://arxiv.org/pdf/1808.00563.pdf (параграф 3.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypGAhUNCI1Sj"
      },
      "outputs": [],
      "source": [
        "noise, noise_sr = torchaudio.load('data/noises/zavod.wav')\n",
        "print(noise.shape, noise_sr)\n",
        "visualize_audio(noise, noise_sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbDvZQykI1Sk"
      },
      "outputs": [],
      "source": [
        "resampled_noise = torchaudio.transforms.Resample(noise_sr, sr)(noise)\n",
        "visualize_audio(resampled_noise, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfL2JLR5I1Sk"
      },
      "outputs": [],
      "source": [
        "background_noise = resampled_noise[..., sr:sr + wav.shape[-1]]\n",
        "visualize_audio(background_noise, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E_W6D49I1Sk"
      },
      "outputs": [],
      "source": [
        "noize_level = torch.Tensor([0])  # [0, 40]\n",
        "\n",
        "noize_energy = torch.norm(background_noise)\n",
        "audio_energy = torch.norm(wav)\n",
        "\n",
        "alpha = (audio_energy / noize_energy) * torch.pow(10, -noize_level / 20)\n",
        "\n",
        "augumented_wav_6 = wav + alpha * background_noise\n",
        "\n",
        "# В некоторых случаях сигнал может выйти за пределы [-1, 1]\n",
        "augumented_wav_6 = torch.clamp(augumented_wav_6, -1, 1)\n",
        "\n",
        "visualize_audio(augumented_wav_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NJl0ueDI1Sk"
      },
      "source": [
        "### SpecAug (частотно-временное маскрование, \"вырезы\" в спектре)\n",
        "\n",
        "Применяются к мел-спектрограмме. `SpecAug` - это аугментации, применяемые к ней так, как будто она представляет собой просто изображение.\n",
        "\n",
        "Детали есть в работе https://arxiv.org/pdf/1904.08779.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afrh3OB7I1Sk"
      },
      "outputs": [],
      "source": [
        "mel_spectrogramer = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=22050,\n",
        "    n_fft=1024,\n",
        "    win_length=1024,\n",
        "    hop_length=256,\n",
        "    n_mels=80,\n",
        ")\n",
        "\n",
        "mel_spectrogram = mel_spectrogramer(wav)\n",
        "log_mel_spectrogram = torch.log(mel_spectrogram).squeeze()\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(log_mel_spectrogram)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZNsLoJrI1Sk"
      },
      "source": [
        "`torchaudio.transforms.FrequencyMasking` добавляет горзонтальную полосу, а `torchaudio.transforms.TimeMasking` вертикальную.\n",
        "\n",
        "Это не единственный возможный способ применять `SpecAug`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTePIA1rI1Sl"
      },
      "outputs": [],
      "source": [
        "specaug = torch.nn.Sequential(\n",
        "    torchaudio.transforms.FrequencyMasking(20),\n",
        "    torchaudio.transforms.TimeMasking(100),\n",
        ")\n",
        "\n",
        "augumented_log_mel_spectrogram = specaug(log_mel_spectrogram)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(augumented_log_mel_spectrogram)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADWZD61aI1Sl"
      },
      "source": [
        "### Задания на самостоятельную работу\n",
        "\n",
        "1. Изучите преобразование `torchaudio.transforms.Preemphasis`. Оно часто применяется для предварительной обработки речевого сигнала в задаче верификации дикторов. Постройте STFT-спектры аудиосигнала LJ001-0001.wav без применения и с применением этого преобразования. Что в них изменяется?\n",
        "2. Попробуйте добавить фоновый шум с помощью преобразования `torchaudio.transforms.AddNoise`. Постройте STFT-спектр фонового шума и зашумленного сигнала.\n",
        "3. Рассмотрите преобразование `torchaudio.transforms.Convolve`. Примените с его помощью импульсную характеристику помещения к нашему аудиосигналу. Постройте STFT-спектр полученного сигнала. Что в нем изменилось по сравнению с оригинальным сигналом, как можно охарактеризовать эти изменения?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}