{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAY4Gy3169wP"
   },
   "source": [
    "# Задание 3\n",
    "\n",
    "https://drive.google.com/file/d/18J1km1ernB-v0MWfxTA7E6BF9DBOQKUs/view?usp=sharing\n",
    "\n",
    "Это задание требует доступа к GPU, поэтому его можно выполнять либо на компьютере с GPU от NVidia, либо в [Google Colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "FcXBeP1O7cnY",
    "outputId": "fea44beb-f455-4898-a53b-5e1aad0be0f4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "from socket import timeout\n",
    "\n",
    "from google.colab import files\n",
    "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "!pip3 install -q torch torchvision\n",
    "!pip3 install -q Pillow==4.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6WGOd1Ct69wU"
   },
   "source": [
    "Сначала давайте скачаем данные с картинками. Это сделает код в следующей ячейке. Данные будут разделены на две части. На обучающей выборке, которая будет храниться в папке **train_kaggle**, мы будем строить наши модели, а на тестовой выборке **test_kaggle** будем предсказывать класс, к которому относится фотография (хотдог или нет).\n",
    "\n",
    "### Если вы в Google Colab!\n",
    "\n",
    "В нем можно запускать ноутбуки с доступом к GPU. Они не очень быстрые, зато бесплатные!\n",
    "Каждый ноутбук получает свой собственный environment c доступным диском итд.\n",
    "\n",
    "Через 90 минут отсуствия активности этот environment пропадает со всеми данными.\n",
    "Поэтому нам придется скачивать данные каждый раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "ourBj07Arm3R",
    "outputId": "b0f80fd5-99ff-46ff-9d84-69f5b38c677a"
   },
   "outputs": [],
   "source": [
    "# Download train data\n",
    "!wget \"https://www.dropbox.com/s/cupinvuotopehty/train.zip?dl=0\"\n",
    "!unzip -q \"train.zip?dl=0\"\n",
    "\n",
    "#local_folder = \"../../HotDogOrNot/content/train_kaggle/\"\n",
    "\n",
    "train_folder = \"train_kaggle/\"\n",
    "# Count number of files in the train folder, should be 4603\n",
    "print('Number of files in the train folder', len(os.listdir(train_folder)))\n",
    "\n",
    "# Download test data\n",
    "!wget \"https://www.dropbox.com/s/7xakfl2r9gn5p1j/test.zip?dl=0\"\n",
    "!unzip -q \"test.zip?dl=0\"\n",
    "\n",
    "test_folder = \"test_kaggle/\"\n",
    "# Count number of files in the test folder, should be 1150\n",
    "print('Number of files in the test folder', len(os.listdir(test_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNU-OD9O9ltP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcC2WP6v69wa"
   },
   "source": [
    "# Имплементируем свой Dataset для загрузки данных\n",
    "\n",
    "В этом задании мы реализуем свой собственный класс Dataset для загрузки данных. Его цель - загрузить данные с диска и выдать по ним тензор с входом сети, меткой и идентификатором картинки (так будет проще подготовить сабмит для kaggle на тестовых данных).\n",
    "\n",
    "Вот ссылка, где хорошо объясняется как это делать на примере: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Ваш Dataset должен в качестве количества сэмплов выдать количество файлов в папке и уметь выдавать кортеж из сэмпла, метки по индексу и названия файла.\n",
    "Если название файла начинается со слов 'frankfurter', 'chili-dog' или 'hotdog' - метка положительная. Иначе отрицательная (ноль).\n",
    "\n",
    "И не забудьте поддержать возможность трансформации входа (аргумент `transforms`), она нам понадобится!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "bN2SPiJa9v5M",
    "outputId": "f4224774-74ab-47f9-a9b5-6ba676fedde6"
   },
   "outputs": [],
   "source": [
    "class HotdogOrNotDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        # TODO: Your code here!\n",
    "        self.folder = folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.folder))\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        # TODO Implement getting item by index\n",
    "        # Hint: os.path.join is helpful!\n",
    "        img_id = os.listdir(self.folder)[index]\n",
    "\n",
    "        img = Image.open(os.path.join(self.folder, img_id))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        y = 1 if img_id.lower().startswith(('frankfurter', 'chili-dog', 'hotdog')) else 0\n",
    "        return img, y, img_id\n",
    "\n",
    "def visualize_samples(dataset, indices, title=None, count=10):\n",
    "    # visualize random 10 samples\n",
    "    plt.figure(figsize=(count*3,3))\n",
    "    display_indices = indices[:count]\n",
    "    if title:\n",
    "        plt.suptitle(\"%s %s/%s\" % (title, len(display_indices), len(indices)))        \n",
    "    for i, index in enumerate(display_indices):    \n",
    "        x, y, _ = dataset[index]\n",
    "        plt.subplot(1,count,i+1)\n",
    "        plt.title(\"Label: %s\" % y)\n",
    "        plt.imshow(x)\n",
    "        plt.grid(False)\n",
    "        plt.axis('off')   \n",
    "    \n",
    "orig_dataset = HotdogOrNotDataset(train_folder)\n",
    "indices = np.random.choice(np.arange(len(orig_dataset)), 7, replace=False)\n",
    "\n",
    "visualize_samples(orig_dataset, indices, \"Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "mQNsUvYm4_2V",
    "outputId": "e6f5e45b-e518-4b53-ac97-0529d8947b1f"
   },
   "outputs": [],
   "source": [
    "# Let's make sure transforms work!\n",
    "dataset = HotdogOrNotDataset(train_folder, transform=transforms.RandomVerticalFlip(0.9))\n",
    "\n",
    "visualize_samples(dataset, indices, \"Samples with flip - a lot should be flipped!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgSnCsln69wh"
   },
   "source": [
    "# Создаем Dataset для тренировки\n",
    "\n",
    "И разделяем его на train и validation.\n",
    "На train будем обучать модель, на validation проверять ее качество, а соревнование Kaggle In-Class проведем на фотографиях из папки test_kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAvkoRx-9FsP"
   },
   "outputs": [],
   "source": [
    "# First, lets load the dataset\n",
    "train_dataset = HotdogOrNotDataset(train_folder, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           # Use mean and std for pretrained models\n",
    "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])                         \n",
    "                       ])\n",
    "                      )\n",
    "test_dataset = HotdogOrNotDataset(test_folder, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           # Use mean and std for pretrained models\n",
    "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])                         \n",
    "                       ])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRnr8CPg7Hli"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "data_size = len(dataset)\n",
    "validation_fraction = .2\n",
    "\n",
    "\n",
    "val_split = int(np.floor((validation_fraction) * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)\n",
    "# Notice that we create test data loader in a different way. We don't have the labels.\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGp-R0k_69wx"
   },
   "source": [
    "Наши обычные функции для тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ek3KVQK7hJ6"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y,_) in enumerate(train_loader):\n",
    "          \n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    # TODO: Copy implementation from previous assignment\n",
    "    # Don't forget to move the data to device before running it through the model!\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for x, y, _ in loader:\n",
    "        x_gpu = x.to(device)\n",
    "        y_gpu = y.to(device)\n",
    "\n",
    "        prediction = model(x_gpu)\n",
    "\n",
    "        _, indices = torch.max(prediction, 1)\n",
    "        correct_samples += torch.sum(indices == y_gpu)\n",
    "        total_samples += y_gpu.shape[0]\n",
    "    \n",
    "    return float(correct_samples) / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6a-3a1ZFGEw_"
   },
   "source": [
    "# Перенос обучения (transfer learning) - тренировать только последний слой\n",
    "\n",
    "Существует несколько вариантов переноса обучения, мы попробуем основные.  \n",
    "Первый вариант - сделать новый последний слой и тренировать только его, заморозив остальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jCWMUWmr7t5g",
    "outputId": "9a37efce-dd47-411f-ec06-37cac01af262"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = # Должны создать\n",
    "\n",
    "model.type(torch.cuda.FloatTensor)\n",
    "model.to(device)\n",
    "\n",
    "parameters = model.parameters()   # Fill the right thing here!\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(parameters, lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFnuevNz69xJ"
   },
   "source": [
    "# Визуализируем метрики и ошибки модели\n",
    "\n",
    "Попробуем посмотреть, где модель ошибается - визуализируем ложные срабатывания (false positives) и ложноотрицательные срабатывания (false negatives).\n",
    "\n",
    "Для этого мы прогоним модель через все примеры и сравним ее с истинными метками (ground truth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieEzZUglJAUB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class SubsetSampler(Sampler):\n",
    "    r\"\"\"Samples elements with given indices sequentially\n",
    "\n",
    "    Arguments:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        indices (ndarray): indices of the samples to take\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in range(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    \n",
    "def evaluate_model(model, dataset, indices):\n",
    "    \"\"\"\n",
    "    Computes predictions and ground truth labels for the indices of the dataset\n",
    "    \n",
    "    Returns: \n",
    "    predictions: np array of booleans of model predictions\n",
    "    grount_truth: np array of boolean of actual labels of the dataset\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    \n",
    "    # TODO: Evaluate model on the list of indices and capture predictions\n",
    "    # and ground truth labels\n",
    "    # Hint: SubsetSampler above could be useful!\n",
    "    \n",
    "    sampler = SubsetSampler(indices)\n",
    "    loader = torch.utils.data.DataLoader(dataset, sampler=sampler)\n",
    "    \n",
    "    predictions, ground_truth = [], []\n",
    "    for x, y, _ in loader:\n",
    "        x_gpu = x.to(device)\n",
    "        y_gpu = y.to(device)\n",
    "\n",
    "        _, indices = torch.max(model(x_gpu), 1)\n",
    "        predictions.append(indices)\n",
    "        ground_truth.append(y_gpu)\n",
    "    \n",
    "    return predictions, ground_truth\n",
    "\n",
    "predictions, gt = evaluate_model(model, train_dataset, val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0bcioK6JBDK"
   },
   "source": [
    "И теперь можно визуализировать false positives и false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "WMmaPfdeKk9H",
    "outputId": "23beae80-dc95-473b-8240-d201f2432f54"
   },
   "outputs": [],
   "source": [
    "false_positive_indices = []\n",
    "false_negatives_indices = []\n",
    "\n",
    "for pred, truth, idx in zip(predictions, gt, val_indices):\n",
    "    if pred and not truth:\n",
    "        false_positive_indices.append(idx)\n",
    "    if not pred and truth:\n",
    "        false_negatives_indices.append(idx)\n",
    "\n",
    "visualize_samples(orig_dataset, false_positive_indices, \"False positives\")\n",
    "visualize_samples(orig_dataset, false_negatives_indices, \"False negatives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JoDeVjN4HZSV",
    "outputId": "915eb081-6546-4d44-f349-54fcdd836887"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def binary_classification_metrics(prediction, ground_truth):\n",
    "    # TODO: Implement this function!\n",
    "    # We did this already it in the assignment1\n",
    "    \n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    N = len(prediction)\n",
    "\n",
    "    for (y_pred, y) in zip(prediction, ground_truth):\n",
    "        if y_pred and y:\n",
    "            TP += 1\n",
    "        if y_pred and not y:\n",
    "            FP += 1\n",
    "        if not y_pred and y:\n",
    "            FN += 1\n",
    "        if not y_pred and not y:\n",
    "            TN += 1\n",
    "\n",
    "    if (TP + FP):\n",
    "        precision = TP / (TP + FP)\n",
    "    if TP + FN:\n",
    "        recall = TP / (TP + FN)\n",
    "    if precision + recall:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "precision, recall, f1 = binary_classification_metrics(predictions, gt)\n",
    "print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (f1, precision, recall))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HotdogOrNot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
